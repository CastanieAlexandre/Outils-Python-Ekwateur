{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outil de concaténation et de classification par cohortes des courbes de charge\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des pods de chaque cohorte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noms_Cohortes=[\"LE CEDRE\",\"CHANEL\",\"Toulouse lot 5\",\"AIH\",\"St-Etienne\",\"Ze Plug AO\"]\n",
    "Cohortes=pd.read_excel(\"Périmètre POD pris en compte pour ARENH 2023 Ekwateur PRO_AOsplit.xlsx\",sheet_name='AO',\n",
    "usecols=Noms_Cohortes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des fichiers csv. Il faut renseigner le chemin du dossier avec toutes les courbes de charge.  \n",
    "C:\\Users\\AlexandreCastanie\\Dropbox (ekwateur)\\Fourniture d'énergie\\4 - PRIX\\23\\23-03\\ELEC\\Prépa CdC Jaunes\\CdC\\tests sur CdC Arenh 23\\3 concaténation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers csv trouvés = 16\n"
     ]
    }
   ],
   "source": [
    "Chemin_dossier_CDC=input(\"Chemin du dossier contenant les csv des courbes de charge\")\n",
    "chemins = []\n",
    "for racine, dirs, fichiers in os.walk(f\"{Chemin_dossier_CDC}\"):\n",
    "    for file in fichiers[:20]:\n",
    "        if file.endswith(\".csv\") and file.startswith(\"Enedis\") and os.path.getsize(racine+\"\\\\\"+file)>=50000:\n",
    "            s = os.path.join(racine, file)\n",
    "            chemins.append(s)\n",
    "print(f\"Nombre de fichiers csv trouvés = {len(chemins)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification des CdC selon leur cohorte et supression des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listes_chemins_cohortes():\n",
    "    l1,l2,l3,l4,l5,l6,lnone,l,luniques,ldoublons=[],[],[],[],[],[],[],[],[],[]\n",
    "    seen=set()\n",
    "    #freq_dict = {}\n",
    "\n",
    "    for chemin_csv in chemins:\n",
    "        num_pod=pd.read_csv(chemin_csv,sep=';',nrows=1,usecols=[0]).loc[0,\"Identifiant PRM\"]\n",
    "        l.append((chemin_csv,num_pod))\n",
    "\n",
    "    # for tup in l:\n",
    "    #     if tup[1] not in freq_dict:\n",
    "    #         freq_dict[tup[1]] = tup\n",
    "    #     else:\n",
    "    #         ldoublons.append(tup)\n",
    "\n",
    "    # luniques = list(freq_dict.values())\n",
    "\n",
    "    for tup in l:\n",
    "        if tup[1] not in seen:\n",
    "            seen.add(tup[1])\n",
    "            luniques.append(tup)\n",
    "        else:\n",
    "            ldoublons.append(tup)\n",
    "            \n",
    "    for ch in luniques:\n",
    "        if ch[1] in Cohortes['LE CEDRE'].tolist():\n",
    "            l1.append((ch[0],ch[1]))\n",
    "        elif ch[1] in Cohortes['CHANEL'].tolist():\n",
    "            l2.append((ch[0],ch[1]))\n",
    "        elif ch[1] in Cohortes['Toulouse lot 5'].tolist():\n",
    "            l3.append((ch[0],ch[1]))\n",
    "        elif ch[1] in Cohortes['AIH'].tolist():\n",
    "            l4.append((ch[0],ch[1]))\n",
    "        elif ch[1] in Cohortes['St-Etienne'].tolist():\n",
    "            l5.append((ch[0],ch[1]))\n",
    "        elif ch[1] in Cohortes['Ze Plug AO'].tolist():\n",
    "            l6.append((ch[0],ch[1]))\n",
    "        else :\n",
    "            lnone.append((ch[0],ch[1]))\n",
    "\n",
    "    return ldoublons,l1,l2,l3,l4,l5,l6,lnone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "liste_doublons,l_LECEDRE,l_CHANEL,l_Tlse,l_AIH,l_StEtienne,l_Ze,lnone=listes_chemins_cohortes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concaténation, rééchantillonnage temporel et somme des valeurs de chaque pod pour chaque cohorte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-01 00:00:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 00:30:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 01:00:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 01:30:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 02:00:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17 21:00:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17 21:30:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17 22:00:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17 22:30:00+01:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-17 23:00:00+01:00</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40271 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2020-11-01 00:00:00+01:00, 2020-11-01 00:30:00+01:00, 2020-11-01 01:00:00+01:00, 2020-11-01 01:30:00+01:00, 2020-11-01 02:00:00+01:00, 2020-11-01 02:30:00+01:00, 2020-11-01 03:00:00+01:00, 2020-11-01 03:30:00+01:00, 2020-11-01 04:00:00+01:00, 2020-11-01 04:30:00+01:00, 2020-11-01 05:00:00+01:00, 2020-11-01 05:30:00+01:00, 2020-11-01 06:00:00+01:00, 2020-11-01 06:30:00+01:00, 2020-11-01 07:00:00+01:00, 2020-11-01 07:30:00+01:00, 2020-11-01 08:00:00+01:00, 2020-11-01 08:30:00+01:00, 2020-11-01 09:00:00+01:00, 2020-11-01 09:30:00+01:00, 2020-11-01 10:00:00+01:00, 2020-11-01 10:30:00+01:00, 2020-11-01 11:00:00+01:00, 2020-11-01 11:30:00+01:00, 2020-11-01 12:00:00+01:00, 2020-11-01 12:30:00+01:00, 2020-11-01 13:00:00+01:00, 2020-11-01 13:30:00+01:00, 2020-11-01 14:00:00+01:00, 2020-11-01 14:30:00+01:00, 2020-11-01 15:00:00+01:00, 2020-11-01 15:30:00+01:00, 2020-11-01 16:00:00+01:00, 2020-11-01 16:30:00+01:00, 2020-11-01 17:00:00+01:00, 2020-11-01 17:30:00+01:00, 2020-11-01 18:00:00+01:00, 2020-11-01 18:30:00+01:00, 2020-11-01 19:00:00+01:00, 2020-11-01 19:30:00+01:00, 2020-11-01 20:00:00+01:00, 2020-11-01 20:30:00+01:00, 2020-11-01 21:00:00+01:00, 2020-11-01 21:30:00+01:00, 2020-11-01 22:00:00+01:00, 2020-11-01 22:30:00+01:00, 2020-11-01 23:00:00+01:00, 2020-11-01 23:30:00+01:00, 2020-11-02 00:00:00+01:00, 2020-11-02 00:30:00+01:00, 2020-11-02 01:00:00+01:00, 2020-11-02 01:30:00+01:00, 2020-11-02 02:00:00+01:00, 2020-11-02 02:30:00+01:00, 2020-11-02 03:00:00+01:00, 2020-11-02 03:30:00+01:00, 2020-11-02 04:00:00+01:00, 2020-11-02 04:30:00+01:00, 2020-11-02 05:00:00+01:00, 2020-11-02 05:30:00+01:00, 2020-11-02 06:00:00+01:00, 2020-11-02 06:30:00+01:00, 2020-11-02 07:00:00+01:00, 2020-11-02 07:30:00+01:00, 2020-11-02 08:00:00+01:00, 2020-11-02 08:30:00+01:00, 2020-11-02 09:00:00+01:00, 2020-11-02 09:30:00+01:00, 2020-11-02 10:00:00+01:00, 2020-11-02 10:30:00+01:00, 2020-11-02 11:00:00+01:00, 2020-11-02 11:30:00+01:00, 2020-11-02 12:00:00+01:00, 2020-11-02 12:30:00+01:00, 2020-11-02 13:00:00+01:00, 2020-11-02 13:30:00+01:00, 2020-11-02 14:00:00+01:00, 2020-11-02 14:30:00+01:00, 2020-11-02 15:00:00+01:00, 2020-11-02 15:30:00+01:00, 2020-11-02 16:00:00+01:00, 2020-11-02 16:30:00+01:00, 2020-11-02 17:00:00+01:00, 2020-11-02 17:30:00+01:00, 2020-11-02 18:00:00+01:00, 2020-11-02 18:30:00+01:00, 2020-11-02 19:00:00+01:00, 2020-11-02 19:30:00+01:00, 2020-11-02 20:00:00+01:00, 2020-11-02 20:30:00+01:00, 2020-11-02 21:00:00+01:00, 2020-11-02 21:30:00+01:00, 2020-11-02 22:00:00+01:00, 2020-11-02 22:30:00+01:00, 2020-11-02 23:00:00+01:00, 2020-11-02 23:30:00+01:00, 2020-11-03 00:00:00+01:00, 2020-11-03 00:30:00+01:00, 2020-11-03 01:00:00+01:00, 2020-11-03 01:30:00+01:00, ...]\n",
       "\n",
       "[40271 rows x 0 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=pd.date_range('11/1/2020', periods=40271, freq='30T')).tz_localize('Europe/Paris',nonexistent='NaT',ambiguous=\"NaT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concaténationPODS2(lchemins):\n",
    "    df=pd.DataFrame()\n",
    "    dfc=pd.DataFrame(index=pd.date_range('11/1/2020', periods=40271, freq='30T')).tz_localize('Europe/Paris',nonexistent='shift_forward')\n",
    "    for ch in lchemins:\n",
    "        df=pd.read_csv(ch[0],sep=';',skiprows=2)\n",
    "        df=df.set_index('Horodate')\n",
    "        df.index=pd.to_datetime(df.index,utc=True).tz_convert('Europe/Paris')\n",
    "        df=df.resample('30T').mean()\n",
    "        df.rename(columns={'Valeur':f\"POD n°{ch[1]}\"},inplace=True)\n",
    "        dfc=dfc.merge(df,how='left', left_index=True, right_index=True)\n",
    "    return dfc.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concaténationPODS(lchemins):\n",
    "    dfc = pd.DataFrame(index=pd.date_range('11/1/2020', periods=40271, freq='30T')).tz_localize('Europe/Paris',nonexistent='NaT',ambiguous=\"NaT\")\n",
    "    for ch in lchemins:\n",
    "        df = pd.read_csv(ch[0], sep=';', skiprows=2, usecols=['Horodate', 'Valeur'])\n",
    "        df = df.set_index('Horodate')\n",
    "        df.index = pd.to_datetime(df.index,utc=True).tz_convert('Europe/Paris')\n",
    "        df = df.resample('30T').mean()\n",
    "        dfc = dfc.join(df.rename(columns={'Valeur': f\"POD n°{ch[1]}\"}))\n",
    "    return dfc.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfLECEDRE= concaténationPODS(l_LECEDRE)\n",
    "dfAIH=concaténationPODS(l_AIH)\n",
    "dfCHANEL=concaténationPODS(l_CHANEL)\n",
    "dfStEtienne=concaténationPODS(l_StEtienne)\n",
    "dfTlse=concaténationPODS(l_Tlse)\n",
    "dfZe=concaténationPODS(l_Ze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfnone=concaténationPODS(lnone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlexandreCastanie\\AppData\\Local\\Temp\\ipykernel_18188\\4062915871.py:2: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  dftot=pd.concat(ldataframes,axis=1,verify_integrity=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18188\\4062915871.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mldataframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfLECEDRE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfCHANEL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfTlse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfAIH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfStEtienne\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfZe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfnone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdftot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldataframes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdftot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdftot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mNoms_Cohortes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNoms_Cohortes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m                 \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"concat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[1;31m# _homogenize ensures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m#  - all(len(x) == len(index) for x in arrays)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    605\u001b[0m                 \u001b[1;31m# Forces alignment. No need to copy data since we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;31m# are putting it into an ndarray later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4670\u001b[0m                 )\n\u001b[0;32m   4671\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"index\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4672\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4674\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4965\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4966\u001b[1;33m         return self._reindex_axes(\n\u001b[0m\u001b[0;32m   4967\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4968\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4985\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4986\u001b[1;33m             obj = obj._reindex_with_indexers(\n\u001b[0m\u001b[0;32m   4987\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4988\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   5030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5031\u001b[0m             \u001b[1;31m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5032\u001b[1;33m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[0;32m   5033\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5034\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[1;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AlexandreCastanie\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_validate_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   4119\u001b[0m         \u001b[1;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4121\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex on an axis with duplicate labels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4123\u001b[0m     def reindex(\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "ldataframes=[dfLECEDRE,dfCHANEL,dfTlse,dfAIH,dfStEtienne,dfZe,dfnone]\n",
    "dftot=pd.concat(ldataframes,axis=1,verify_integrity=True)\n",
    "dftot=dftot.rename(columns={i:Noms_Cohortes[i] for i in range(len(Noms_Cohortes))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdoublons=pd.DataFrame({\"N° PODS en doubles supprimés\":[i[1] for i in liste_doublons],\"chemins\":[i[0] for i in liste_doublons]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(Chemin_dossier_CDC+\"\\\\CdC PODs jaunes test.xlsx\") as writer:\n",
    "    dftot.to_excel(writer,sheet_name=\"CdC\", startrow=1)\n",
    "    dfdoublons.to_excel(writer,sheet_name=\"Doublons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enedis_SGE_HDM_A07SY4G9.csv\n"
     ]
    }
   ],
   "source": [
    "print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ca7da86a5746769277311321674abaf2fc79cfd8d8ef3caf2e68cf5b6e6d43b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
